---
abstract: |-
  Low-cost, smartphone-powered VR/AR headsets are becoming more popular. These basic devices – little more than plastic or cardboard shells – lack advanced features, such as controllers for the hands, limiting their interactive capability. Moreover, even high-end consumer headsets lack the ability to track the body and face. For this reason, interactive experiences like social VR are underdeveloped. We introduce MeCap, which enables commodity VR headsets to be augmented with powerful motion capture (“MoCap”) and user-sensing capabilities at very low cost (under $5). Using only a pair of hemi-spherical mirrors and the existing rear-facing camera of a smartphone, MeCap provides real-time estimates of a wearer’s 3D body pose, hand pose, facial expression, physical appearance and surrounding environment – capabilities which are either absent in contemporary VR/AR systems or which require specialized hardware and controllers. We evaluate the accuracy of each of our tracking features, the results of which show imminent feasibility.
authors:
- ahuja
- Chris Harrison
- goel
- Robert Xiao
caption: ''
citation: |-
  Karan Ahuja, Chris Harrison, Mayank Goel, and Robert Xiao. 2019. MeCap: Whole-Body Digitization for Low-Cost VR/AR Headsets. In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology (UIST '19). ACM, New York, NY, USA, 453-462. DOI: https://doi.org/10.1145/3332165.3347889
conference: UIST 2019
date: '2019-10-1'
image: '/images/pubs/mecap.png'
pdf: /pdfs/mecap.pdf
thumbnail: '/images/pubs/mecap.png'
name: 'Mecap'
title: 'MeCap: Whole-Body Digitization for Low-Cost VR/AR Headsets'
video: 'https://youtu.be/mR84i0HvzwM'
video_embed: '<iframe width="560" height="315" src="https://www.youtube.com/embed/mR84i0HvzwM" frameborder="0" allowfullscreen></iframe>'
onhomepage: false
blurb: Low-cost approach to capture whole-body pose on AR/VR headsets
award: Honorable Mention Award
category: interaction
---
