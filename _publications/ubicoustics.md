---
abstract: |-
  Despite sound being a rich source of information, computing devices with microphones do not leverage audio to glean useful insights about their physical and social context. For example, a smart speaker sitting on a kitchen countertop cannot figure out if it is in a kitchen, let alone know what a user is doing in a kitchen â€“ a missed opportunity. In this work, we describe a novel, real-time, sound-based activity recognition system. We start by taking an existing, state-of-the-art sound labeling model, which we then tune to classes of interest by drawing data from professional sound effect libraries traditionally used in the entertainment industry. These well-labeled and high-quality sounds are the perfect atomic unit for data augmentation, including amplitude, reverb, and mixing, allowing us to exponentially grow our tuning data in realistic ways. We quantify the performance of our approach across a range of environments and device categories and show that microphone-equipped computing devices already have the requisite capability to unlock real-time activity recognition comparable to human accuracy.
authors:
- Gierad Laput
- ahuja
- goel
- Chris Harrison
bibtex: |-
  @inproceedings{laput2018ubicoustics,
    title={Ubicoustics: Plug-and-Play Acoustic Activity Recognition},
    author={Laput, Gierad and Ahuja, Karan and Goel, Mayank and Harrison, Chris},
    booktitle={The 31st Annual ACM Symposium on User Interface Software and Technology},
    pages={213--224},
    year={2018},
    organization={ACM}
  }
citation: |-
  Gierad Laput, Karan Ahuja, Mayank Goel, and Chris Harrison. 2018. Ubicoustics: Plug-and-Play Acoustic Activity Recognition. In Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology (UIST '18). ACM, New York, NY, USA, 213-224. DOI: https://doi.org/10.1145/3242587.3242609
conference: Conference on Human Factors in Computing Systems (CHI), 2016
date: '2018-10-14'
image: '/images/pubs/ubicoustics.png'
pdf: /pdfs/ubicoustics.pdf
thumbnail: '/images/pubs/ubicoustics.png'
name: 'Ubicoustics'
title: 'Ubicoustics: Plug-and-Play Acoustic Activity Recognition'
video: 'https://youtu.be/N5ZaBeB07u4'
video_embed: '<iframe width="560" height="315" src="https://www.youtube.com/embed/N5ZaBeB07u4" frameborder="0" allowfullscreen></iframe>'
onhomepage: false
blurb: Immediately deployable activity recognition using microphones and deep learning models trained on existing datasets
code: https://github.com/FIGLAB/ubicoustics
category: activity
---
