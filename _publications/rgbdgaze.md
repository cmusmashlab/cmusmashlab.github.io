---
abstract: |-
 Tracking a user’s gaze on smartphones offers the potential for accessible and powerful multimodal interactions. However, phones are used in a myriad of contexts and state-of-the-art gaze models that use only the front-facing RGB cameras are too coarse and do not adapt adequately to changes in context. While prior research has showcased the efficacy of depth maps for gaze tracking, they have been limited to desktop-grade depth cameras, which are more capable than the types seen in smartphones, that must be thin and low-powered. In this paper, we present a gaze tracking system that makes use of today’s smartphone depth camera technology to adapt to the changes in distance and orientation relative to the user’s face. Unlike prior efforts that used depth sensors, we do not constrain the users to maintain a fixed head position. Our approach works across different use contexts in unconstrained mobile settings. The results show that our multimodal ML model has a mean gaze error of 1.89 cm; a 16.3% improvement over using RGB data alone (2.26 cm error). Our system and dataset offer the first benchmark of gaze tracking on smartphones using RGB+Depth data under different use contexts.
authors:
- arakawa
- goel
- Chris Harrison
- ahuja
caption: ''
citation: |-
  Riku Arakawa, Mayank Goel, Chris Harrison, Karan Ahuja. 2022. RGBDGaze: Gaze Tracking on Smartphones with RGB and Depth Data In Proceedings of the 2022 International Conference on Multimodal Interaction (ICMI '22). Association for Computing Machinery, New York, NY, USA.
conference: Proceedings of the International Conference on Multimodal Interaction (ICMI)
date: '2022-10-10'
image: '/images/pubs/rgbdgaze.png'
pdf: /pdfs/rgbdgaze.pdf
thumbnail: '/images/pubs/rgbdgaze.png'
name: 'RGBD Gaze'
title: 'RGBDGaze: Gaze Tracking on Smartphones with RGB and Depth Data'
video: 'https://youtu.be/-HwcmWRAsaA'
video_embed: '<iframe width="560" height="315" src="https://www.youtube.com/embed/-HwcmWRAsaA" frameborder="0" allowfullscreen></iframe>'
onhomepage: true
blurb: Gaze tracking with RGB and Depth Data
---
